{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe827dd7",
   "metadata": {},
   "source": [
    "# Aim : - Feature Scaling and Dummification\n",
    "\n",
    "# Perform feature dummification to convert categorical variables into numerical representations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554755e5",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad1b8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CATEGORICAL AND IMBALANCED DATA\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer \n",
    "from sklearn.feature_extraction import DictVectorizer \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 1. Load the Dataset\n",
    "\n",
    "df = pd.read_csv('kc_house_data.csv')\n",
    "\n",
    "# --- 2. Define Features for the tasks ---\n",
    "NOMINAL_FEATURE = 'zipcode'\n",
    "ORDINAL_FEATURE = 'grade'\n",
    "IMBALANCED_TARGET = 'waterfront' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e603478",
   "metadata": {},
   "source": [
    "# Encoding Nominal Categorical Features (Using LabelBinarizer )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16ad9a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Encoding Nominal Categorical Feature: LabelBinarizer (zipcode) ---\n",
      "Shape of encoded array: (100, 49)\n",
      "First 5 rows of one-hot encoded array:\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "\n",
      "--- Using pandas get_dummies (as per Page 2) ---\n",
      "First 5 rows of pandas get_dummies output:\n",
      "   zipcode_98001  zipcode_98002  zipcode_98003  zipcode_98004  zipcode_98005  \\\n",
      "0              0              0              0              0              0   \n",
      "1              0              0              0              0              0   \n",
      "2              0              0              0              0              0   \n",
      "3              0              0              0              0              0   \n",
      "4              0              0              0              0              0   \n",
      "\n",
      "   zipcode_98006  zipcode_98007  zipcode_98008  zipcode_98010  zipcode_98011  \\\n",
      "0              0              0              0              0              0   \n",
      "1              0              0              0              0              0   \n",
      "2              0              0              0              0              0   \n",
      "3              0              0              0              0              0   \n",
      "4              0              0              0              0              0   \n",
      "\n",
      "   ...  zipcode_98146  zipcode_98148  zipcode_98155  zipcode_98166  \\\n",
      "0  ...              0              0              0              0   \n",
      "1  ...              0              0              0              0   \n",
      "2  ...              0              0              0              0   \n",
      "3  ...              0              0              0              0   \n",
      "4  ...              0              0              0              0   \n",
      "\n",
      "   zipcode_98168  zipcode_98177  zipcode_98178  zipcode_98188  zipcode_98198  \\\n",
      "0              0              0              1              0              0   \n",
      "1              0              0              0              0              0   \n",
      "2              0              0              0              0              0   \n",
      "3              0              0              0              0              0   \n",
      "4              0              0              0              0              0   \n",
      "\n",
      "   zipcode_98199  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "\n",
      "[5 rows x 70 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Encoding Nominal Categorical Feature: LabelBinarizer (zipcode) ---\")\n",
    "# Use only the first 100 rows to limit the number of zipcodes for cleaner output\n",
    "nominal_feature_array = df[NOMINAL_FEATURE].head(100).values.reshape(-1, 1)\n",
    "\n",
    "# Create one-hot encoder\n",
    "one_hot = LabelBinarizer()\n",
    "\n",
    "# One-hot encode feature\n",
    "one_hot_encoded = one_hot.fit_transform(nominal_feature_array)\n",
    "\n",
    "print(\"Shape of encoded array:\", one_hot_encoded.shape)\n",
    "print(\"First 5 rows of one-hot encoded array:\")\n",
    "print(one_hot_encoded[:5])\n",
    "\n",
    "print(\"\\n--- Using pandas get_dummies (as per Page 2) ---\")\n",
    "# This is generally the preferred method in a Data Science workflow\n",
    "dummy_features = pd.get_dummies(df[NOMINAL_FEATURE], prefix=NOMINAL_FEATURE, dtype=int)\n",
    "print(\"First 5 rows of pandas get_dummies output:\")\n",
    "print(dummy_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23869fea",
   "metadata": {},
   "source": [
    "# 5.2 Encoding Ordinal Categorical Features (Using DataFrame replace method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34b758f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 5.2 Encoding Ordinal Categorical Features: grade ---\n",
      "Original grade vs New Ordinal Scale (First 5 rows):\n",
      "  Grade_Text  Grade_Ordinal\n",
      "0     Medium              2\n",
      "1     Medium              2\n",
      "2     Medium              2\n",
      "3     Medium              2\n",
      "4     Medium              2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Swati\\AppData\\Local\\Temp\\ipykernel_25368\\3088304848.py:22: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_ordinal['Grade_Ordinal'] = df_ordinal['Grade_Text'].replace(scale_mapper)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- 5.2 Encoding Ordinal Categorical Features: {ORDINAL_FEATURE} ---\")\n",
    "\n",
    "# The 'grade' feature is already numerical (1-13) but can be re-mapped for demonstration\n",
    "# We will treat 1-5 as 'Low', 6-8 as 'Medium', 9-13 as 'High' for this example\n",
    "df_ordinal = df[[ORDINAL_FEATURE]].copy()\n",
    "\n",
    "# Create mapper\n",
    "grade_mapper = {\n",
    "    g: 'Low' if g <= 5 else ('Medium' if g <= 8 else 'High') \n",
    "    for g in df_ordinal[ORDINAL_FEATURE].unique()\n",
    "}\n",
    "df_ordinal['Grade_Text'] = df_ordinal[ORDINAL_FEATURE].replace(grade_mapper)\n",
    "\n",
    "# Define the ordinal numerical replacement\n",
    "scale_mapper = {\n",
    "    \"Low\": 1,\n",
    "    \"Medium\": 2,\n",
    "    \"High\": 3\n",
    "}\n",
    "\n",
    "# Replace feature values with scale\n",
    "df_ordinal['Grade_Ordinal'] = df_ordinal['Grade_Text'].replace(scale_mapper)\n",
    "\n",
    "print(f\"Original {ORDINAL_FEATURE} vs New Ordinal Scale (First 5 rows):\")\n",
    "print(df_ordinal[['Grade_Text', 'Grade_Ordinal']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f206e422",
   "metadata": {},
   "source": [
    "# Encoding Dictionaries of Features (DictVectorizer)\n",
    "# (Adaptation uses existing data structured as a dictionary list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5caba6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Encoding Dictionaries of Features: DictVectorizer ---\n",
      "First 5 rows of DictVectorizer output:\n",
      "[[221900.   1180.]\n",
      " [538000.   2570.]\n",
      " [180000.    770.]\n",
      " [604000.   1960.]\n",
      " [510000.   1680.]]\n",
      "Feature Names: ['price' 'sqft_living']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Encoding Dictionaries of Features: DictVectorizer ---\")\n",
    "# Create a sample list of dictionaries from 'price' and 'sqft_living'\n",
    "data_dict = df[['price', 'sqft_living']].head(5).to_dict('records')\n",
    "\n",
    "# Create dictionary vectorizer\n",
    "dictvectorizer = DictVectorizer(sparse=False)\n",
    "\n",
    "# Convert dictionary to feature matrix\n",
    "features_dict_vec = dictvectorizer.fit_transform(data_dict)\n",
    "\n",
    "print(\"First 5 rows of DictVectorizer output:\")\n",
    "print(features_dict_vec)\n",
    "print(\"Feature Names:\", dictvectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb96242b",
   "metadata": {},
   "source": [
    "# Imputing Missing Class Values: Most Frequent (SimpleImputer)\n",
    "# (Adaptation uses the 'zipcode' feature after adding an artificial NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5959b69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Imputing Missing Class Values: Most Frequent (SimpleImputer) ---\n",
      "Original Feature Array (with NaN at index 3):\n",
      "[98178. 98125. 98028.    nan 98074. 98053. 98003. 98198. 98146. 98038.]\n",
      "Imputed Feature Array (NaN replaced by most frequent value):\n",
      "[98178. 98125. 98028. 98003. 98074. 98053. 98003. 98198. 98146. 98038.]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Imputing Missing Class Values: Most Frequent (SimpleImputer) ---\")\n",
    "\n",
    "# Create a copy and add a missing value for demonstration\n",
    "zip_codes_missing = df[NOMINAL_FEATURE].head(10).copy()\n",
    "zip_codes_missing.loc[3] = np.nan # Introduce a missing value\n",
    "\n",
    "# Convert to 2D array required by SimpleImputer\n",
    "zip_codes_array = zip_codes_missing.values.reshape(-1, 1)\n",
    "\n",
    "# Create imputer (strategy='most_frequent')\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent') \n",
    "\n",
    "# Impute values\n",
    "imputed_zip_codes = imputer.fit_transform(zip_codes_array)\n",
    "\n",
    "print(\"Original Feature Array (with NaN at index 3):\")\n",
    "print(zip_codes_array.flatten())\n",
    "print(\"Imputed Feature Array (NaN replaced by most frequent value):\")\n",
    "print(imputed_zip_codes.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76d3d11",
   "metadata": {},
   "source": [
    "# Handling Imbalanced Classes: Class Weighting (RandomForestClassifier)\n",
    "# Using the highly imbalanced 'waterfront' target (IMBALANCED_TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d139734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Handling Imbalanced Classes: Class Weighting ---\n",
      "Class 0 (No Waterfront): 21450 (99.25%)\n",
      "Class 1 (Waterfront): 163 (0.75%)\n",
      "\n",
      "RandomForestClassifier created using class_weight='balanced'\n",
      "\n",
      "--- Downsampling (Majority Class) ---\n",
      "New Downsampled Dataset Size: 326\n",
      "New Class 0 Count: 163\n",
      "New Class 1 Count: 163\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Handling Imbalanced Classes: Class Weighting ---\")\n",
    "\n",
    "# Define target and features (using raw features for simplicity)\n",
    "y_target = df[IMBALANCED_TARGET].values\n",
    "X_features = df[['sqft_living', 'price']].values\n",
    "\n",
    "# 1. Calculate the class distribution\n",
    "class_0_count = np.sum(y_target == 0)\n",
    "class_1_count = np.sum(y_target == 1)\n",
    "total_count = len(y_target)\n",
    "\n",
    "# Display imbalance\n",
    "print(f\"Class 0 (No Waterfront): {class_0_count} ({class_0_count/total_count:.2%})\")\n",
    "print(f\"Class 1 (Waterfront): {class_1_count} ({class_1_count/total_count:.2%})\")\n",
    "\n",
    "# 2. Create the classifier with balanced class weights (as per Page 7)\n",
    "clf_balanced = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "print(\"\\nRandomForestClassifier created using class_weight='balanced'\")\n",
    "# You would then fit this model: clf_balanced.fit(X_features, y_target)\n",
    "\n",
    "# 3. Demonstration of Downsampling (as per Page 7)\n",
    "\n",
    "# Identify indices for each class\n",
    "i_class0 = np.where(y_target == 0)[0]\n",
    "i_class1 = np.where(y_target == 1)[0]\n",
    "n_class1 = len(i_class1)\n",
    "\n",
    "# Downsample the majority class (Class 0) to match the size of the minority class (Class 1)\n",
    "i_class0_downsampled = np.random.choice(i_class0, size=n_class1, replace=False)\n",
    "\n",
    "# Create the downsampled target and feature matrices\n",
    "target_downsampled = np.hstack((y_target[i_class0_downsampled], y_target[i_class1]))\n",
    "features_downsampled = np.vstack((X_features[i_class0_downsampled, :], X_features[i_class1, :]))\n",
    "\n",
    "print(\"\\n--- Downsampling (Majority Class) ---\")\n",
    "print(f\"New Downsampled Dataset Size: {len(target_downsampled)}\")\n",
    "print(f\"New Class 0 Count: {np.sum(target_downsampled == 0)}\")\n",
    "print(f\"New Class 1 Count: {np.sum(target_downsampled == 1)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
