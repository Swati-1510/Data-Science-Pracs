{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e3d4951",
   "metadata": {},
   "source": [
    "#  **SHETH L.U.J. & SIR M.V. COLLEGE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7c1690",
   "metadata": {},
   "source": [
    " # Swati Mahajan T093"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8a5713",
   "metadata": {},
   "source": [
    "# Practical No . 09"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbd1392",
   "metadata": {},
   "source": [
    "**Principal Component Analysis (PCA)**\n",
    "* Perform PCA on a dataset to reduce dimensionality.\n",
    "* Evaluate the explained variance and select the appropriate number of principal components.\n",
    "* Visualize the data in the reduced-dimensional space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4d9699",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9b4fd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# 1. SETUP: Load and Prepare Data\n",
    "df = pd.read_csv('kc_house_data.csv')\n",
    "\n",
    "# --- Define Features (X) and Target (y) ---\n",
    "FEATURE_COLUMNS = ['sqft_living', 'sqft_lot', 'price', 'yr_built']\n",
    "X = df[FEATURE_COLUMNS].values # Features for PCA/LDA\n",
    "\n",
    "# Create a simplified 3-class target 'y' for LDA (supervised method)\n",
    "# Low (grade <= 6), Medium (grade 7-9), High (grade >= 10)\n",
    "y = np.select(\n",
    "    [df['grade'] <= 6, (df['grade'] >= 7) & (df['grade'] <= 9), df['grade'] >= 10],\n",
    "    [0, 1, 2]\n",
    ")\n",
    "\n",
    "# Standardize the feature matrix (MANDATORY for PCA/LDA)\n",
    "scaler = StandardScaler()\n",
    "X_standardized = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5626c32",
   "metadata": {},
   "source": [
    "# Reducing Features Using Principal Components (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d80748fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Principal Component Analysis (PCA) ---\n",
      "Original number of features: 4\n",
      "Reduced number of features: 3\n",
      "Variance Explained by the components: 0.9388\n",
      "\n",
      "First 5 rows of the Reduced Feature Matrix (X_pca):\n",
      "[[-1.42881554 -0.00901084  0.13673587]\n",
      " [ 0.10451991 -0.60896498  0.2731242 ]\n",
      " [-2.01604461 -0.32835442  0.71387946]\n",
      " [-0.10136385 -0.34515009 -0.02243807]\n",
      " [-0.21605382  0.32648514 -0.46824389]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Principal Component Analysis (PCA) ---\")\n",
    "\n",
    "# Create a PCA that will retain 90% of the variance\n",
    "# n_components=0.90 means 'keep enough components to explain 90% of the variance'\n",
    "pca = PCA(n_components=0.90)\n",
    "\n",
    "# Conduct PCA (Fit and transform the standardized data)\n",
    "X_pca = pca.fit_transform(X_standardized)\n",
    "\n",
    "# Show results\n",
    "print(f\"Original number of features: {X_standardized.shape[1]}\")\n",
    "print(f\"Reduced number of features: {X_pca.shape[1]}\")\n",
    "print(f\"Variance Explained by the components: {pca.explained_variance_ratio_.sum():.4f}\")\n",
    "print(\"\\nFirst 5 rows of the Reduced Feature Matrix (X_pca):\")\n",
    "print(X_pca[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4e632d",
   "metadata": {},
   "source": [
    "# Reducing Features When Data Is Linearly Inseparable (KernelPCA)\n",
    "NOTE : KernelPCA is often used for non-linear data like image or text, but we demonstrate it here using the same features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ca7d514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Kernel PCA (KPCA) ---\n",
      "Original number of features: 4\n",
      "Reduced number of features (n_components=2): 2\n",
      "\n",
      "First 5 rows of the Reduced Feature Matrix (X_kpca):\n",
      "[[ 0.60642762  0.17693025]\n",
      " [ 0.08674685 -0.18320531]\n",
      " [ 0.34381513 -0.24840479]\n",
      " [ 0.11414948  0.11168343]\n",
      " [-0.299246    0.45622665]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Kernel PCA (KPCA) ---\")\n",
    "\n",
    "# Create a KernelPCA that will reduce the data to 2 components\n",
    "kpca = KernelPCA(kernel=\"rbf\", gamma=1, n_components=2)\n",
    "\n",
    "# Conduct KPCA\n",
    "X_kpca = kpca.fit_transform(X_standardized)\n",
    "\n",
    "# Show results\n",
    "print(f\"Original number of features: {X_standardized.shape[1]}\")\n",
    "print(f\"Reduced number of features (n_components=2): {X_kpca.shape[1]}\")\n",
    "print(\"\\nFirst 5 rows of the Reduced Feature Matrix (X_kpca):\")\n",
    "print(X_kpca[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2417e08",
   "metadata": {},
   "source": [
    "# Reducing Features by Maximizing Class Separability (LDA)\n",
    "Note: The maximum number of components in LDA is C-1, where C is the number of classes.\n",
    "\n",
    "Our target 'y' has 3 classes (0, 1, 2), so max components is 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de722b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Linear Discriminant Analysis (LDA) ---\n",
      "Original number of features: 4\n",
      "Reduced number of features (max possible): 2\n",
      "Ratio of explained variance by each component:\n",
      "[0.93295347 0.06704653]\n",
      "\n",
      "First 5 rows of the Reduced Feature Matrix (X_lda):\n",
      "[[ 1.44850459  0.03845149]\n",
      " [-0.08615062  0.42678322]\n",
      " [ 2.11780599  0.70507866]\n",
      " [ 0.05533933  0.23678207]\n",
      " [ 0.13481206 -0.47797024]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Linear Discriminant Analysis (LDA) ---\")\n",
    "\n",
    "# Create an LDA that will reduce the data down to 2 feature (max possible)\n",
    "lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "\n",
    "# Run LDA and use it to transform the features\n",
    "X_lda = lda.fit(X_standardized, y).transform(X_standardized)\n",
    "\n",
    "# Print the number of features\n",
    "print(f\"Original number of features: {X_standardized.shape[1]}\")\n",
    "print(f\"Reduced number of features (max possible): {X_lda.shape[1]}\")\n",
    "\n",
    "# View the ratio of explained variance\n",
    "print(\"Ratio of explained variance by each component:\")\n",
    "print(lda.explained_variance_ratio_)\n",
    "\n",
    "print(\"\\nFirst 5 rows of the Reduced Feature Matrix (X_lda):\")\n",
    "print(X_lda[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
