{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e632d4f",
   "metadata": {},
   "source": [
    "# Aim : - Feature Scaling and Dummification\n",
    "# Apply feature-scaling techniques like standardization and normalization to numerical features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d9268b",
   "metadata": {},
   "source": [
    " # Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f025a83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, Normalizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 1. Load the Dataset (Assuming 'kc_house_data.csv' is present)\n",
    "df = pd.read_csv('kc_house_data.csv')\n",
    "\n",
    "# --- 2. Define and Prepare Features ---\n",
    "\n",
    "# Numerical Features for Scaling/Clustering/Imputation\n",
    "NUMERICAL_FEATURES = ['sqft_living', 'sqft_lot', 'yr_built', 'price']\n",
    "features_all = df[NUMERICAL_FEATURES].values\n",
    "\n",
    "# Categorical Feature for Dummification\n",
    "CATEGORICAL_FEATURE_NAME = 'condition'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786c9a63",
   "metadata": {},
   "source": [
    "\n",
    "# 4.1 Rescaling a feature: MinMaxScaler (Normalization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3ba750a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 4.1 Rescaling: MinMaxScaler ---\n",
      "First 5 rows of the scaled features array (MinMaxScaler):\n",
      "[[0.06716981 0.00310751 0.47826087 0.01926557]\n",
      " [0.17207547 0.00407187 0.44347826 0.06072131]\n",
      " [0.03622642 0.00574253 0.28695652 0.01377049]\n",
      " [0.12603774 0.00271377 0.56521739 0.06937705]\n",
      " [0.10490566 0.00457949 0.75652174 0.05704918]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- 4.1 Rescaling: MinMaxScaler ---\")\n",
    "minmax_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_features_minmax = minmax_scaler.fit_transform(features_all)\n",
    "print(\"First 5 rows of the scaled features array (MinMaxScaler):\")\n",
    "print(scaled_features_minmax[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ae3cf7",
   "metadata": {},
   "source": [
    "# 4.2 Standardizing a Feature: StandardScaler & RobustScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3cf2cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 4.2 Standardizing: StandardScaler ---\n",
      "First 5 rows of the standardized features array:\n",
      "[[-0.97983502 -0.22832133 -0.54489777 -0.86671733]\n",
      " [ 0.53363434 -0.18988538 -0.6810785  -0.00568792]\n",
      " [-1.42625404 -0.12329847 -1.29389179 -0.98084935]\n",
      " [-0.13055006 -0.2440144  -0.20444594  0.17409044]\n",
      " [-0.43542158 -0.16965339  0.54454807 -0.08195753]]\n",
      "\n",
      "--- 4.2 Standardizing: RobustScaler ---\n",
      "First 5 rows of the Robust Scaled features array:\n",
      "[[-0.65004452 -0.34844193 -0.43478261 -0.70608265]\n",
      " [ 0.58771149 -0.06657224 -0.52173913  0.27240365]\n",
      " [-1.01513802  0.42174221 -0.91304348 -0.83578393]\n",
      " [ 0.0445236  -0.46352691 -0.2173913   0.47670639]\n",
      " [-0.20480855  0.08179887  0.26086957  0.18572976]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- 4.2 Standardizing: StandardScaler ---\")\n",
    "standard_scaler = StandardScaler()\n",
    "standardized_features = standard_scaler.fit_transform(features_all)\n",
    "print(\"First 5 rows of the standardized features array:\")\n",
    "print(standardized_features[:5])\n",
    "\n",
    "print(\"\\n--- 4.2 Standardizing: RobustScaler ---\")\n",
    "robust_scaler = RobustScaler()\n",
    "robust_scaled_features = robust_scaler.fit_transform(features_all)\n",
    "print(\"First 5 rows of the Robust Scaled features array:\")\n",
    "print(robust_scaled_features[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2fcbc0",
   "metadata": {},
   "source": [
    "# 4.3 Normalizing Observations: Normalizer\n",
    "# (Note: This is rarely used on raw feature data, but here for completeness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c848486e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 4.3 Normalizing Observations: Normalizer (L2 Norm) ---\n",
      "First 5 rows of the Normalized features array (L2 Norm):\n",
      "[[0.00531571 0.02545232 0.00880695 0.99962311]\n",
      " [0.00477643 0.01345951 0.003626   0.99989143]\n",
      " [0.00427091 0.05546633 0.01072164 0.99839386]\n",
      " [0.00324489 0.00827777 0.00325317 0.99995518]\n",
      " [0.00329366 0.01584094 0.00389554 0.99986151]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- 4.3 Normalizing Observations: Normalizer (L2 Norm) ---\")\n",
    "normalizer = Normalizer(norm=\"l2\")\n",
    "normalized_features = normalizer.transform(features_all)\n",
    "\n",
    "print(\"First 5 rows of the Normalized features array (L2 Norm):\")\n",
    "print(normalized_features[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b41048",
   "metadata": {},
   "source": [
    "# Feature Dummification (Not in original doc headings, but required)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d287ff7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Feature Dummification: condition (One-Hot Encoding) ---\n",
      "First 5 rows of Dummified Features:\n",
      "   condition_1  condition_2  condition_3  condition_4  condition_5\n",
      "0            0            0            1            0            0\n",
      "1            0            0            1            0            0\n",
      "2            0            0            1            0            0\n",
      "3            0            0            0            0            1\n",
      "4            0            0            1            0            0\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- Feature Dummification: {CATEGORICAL_FEATURE_NAME} (One-Hot Encoding) ---\")\n",
    "dummy_features = pd.get_dummies(df[CATEGORICAL_FEATURE_NAME], \n",
    "                               prefix=CATEGORICAL_FEATURE_NAME, \n",
    "                               dtype=int)\n",
    "print(\"First 5 rows of Dummified Features:\")\n",
    "print(dummy_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5e269c",
   "metadata": {},
   "source": [
    "# 4.9 Grouping Observations Using Clustering: KMeans\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1019f2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 4.9 Grouping Observations Using Clustering: KMeans ---\n",
      "First 5 rows with new 'cluster_group' column:\n",
      "      price  sqft_living  cluster_group\n",
      "0  221900.0         1180              0\n",
      "1  538000.0         2570              0\n",
      "2  180000.0          770              0\n",
      "3  604000.0         1960              0\n",
      "4  510000.0         1680              2\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- 4.9 Grouping Observations Using Clustering: KMeans ---\")\n",
    "# Use the scaled data for clustering\n",
    "clusterer = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "# Fit the clusterer to the standardized data\n",
    "clusterer.fit(standardized_features)\n",
    "# Predict the cluster group for each house\n",
    "df['cluster_group'] = clusterer.predict(standardized_features)\n",
    "\n",
    "print(\"First 5 rows with new 'cluster_group' column:\")\n",
    "print(df[['price', 'sqft_living', 'cluster_group']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab31e26",
   "metadata": {},
   "source": [
    "# 4.10 Deleting Observations with Missing Values\n",
    "# 4.11 Imputing Missing Values (Demonstration)\n",
    "# (Using the original DataFrame 'df' for simplicity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5af5d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 4.10 Deleting Observations with Missing Values ---\n",
      "Original Row Count: 21613\n",
      "Cleaned Row Count (after dropna): 21611\n",
      "\n",
      "--- 4.11 Imputing Missing Values (Mean Imputation) ---\n",
      "Shape of Imputed Array (no missing values): (21613, 4)\n",
      "Mean Imputed Value for the first missing 'sqft_lot' (Index 10, Column 1): 15107.21\n"
     ]
    }
   ],
   "source": [
    "# --- Create a copy of the dataframe and manually add a missing value for demonstration ---\n",
    "df_missing = df.copy()\n",
    "# Simulate a missing value (e.g., a missing 'sqft_lot' for the 10th house)\n",
    "df_missing.loc[10, 'sqft_lot'] = np.nan \n",
    "# Also simulate a missing 'price' for the 15th house\n",
    "df_missing.loc[15, 'price'] = np.nan \n",
    "\n",
    "print(\"\\n--- 4.10 Deleting Observations with Missing Values ---\")\n",
    "# df.dropna() removes any row that contains at least one NaN (missing) value\n",
    "df_cleaned = df_missing.dropna()\n",
    "\n",
    "print(f\"Original Row Count: {len(df_missing)}\")\n",
    "print(f\"Cleaned Row Count (after dropna): {len(df_cleaned)}\")\n",
    "\n",
    "\n",
    "print(\"\\n--- 4.11 Imputing Missing Values (Mean Imputation) ---\")\n",
    "# Imputer is deprecated, SimpleImputer is the modern equivalent\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "# Fit and transform the numerical features array\n",
    "imputed_features = imputer.fit_transform(df_missing[NUMERICAL_FEATURES])\n",
    "\n",
    "print(f\"Shape of Imputed Array (no missing values): {imputed_features.shape}\")\n",
    "print(f\"Mean Imputed Value for the first missing 'sqft_lot' (Index 10, Column 1): {imputed_features[10, 1]:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
